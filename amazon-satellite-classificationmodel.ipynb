{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datetime import datetime\nfrom datetime import timedelta\nimport os\nimport math\nimport statistics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom IPython.display import clear_output\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\nimport tensorflow_addons as tfa\n\n# tf.test.is_gpu_available()\n# tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:34:56.013842Z","iopub.execute_input":"2022-06-11T22:34:56.014994Z","iopub.status.idle":"2022-06-11T22:35:03.284663Z","shell.execute_reply.started":"2022-06-11T22:34:56.014835Z","shell.execute_reply":"2022-06-11T22:35:03.283712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Def functions: One-Hot Encoding and Split Data (Dataframe)","metadata":{}},{"cell_type":"code","source":"def Get_ListOfLabels(df_InputLabels):\n    df_Tags = df_InputLabels.str.split(expand=True)\n    columns = len(df_Tags.columns)\n\n    for i in range(columns):\n        if i == 0:\n            df_aux = pd.DataFrame(df_Tags[0])\n        else:\n            df_aux = df_aux.append(pd.DataFrame(df_Tags[i].rename(index=0)))\n\n    LabelList = (df_aux.drop_duplicates().sort_values([0], ascending=[True]))[0].tolist()\n    LabelList = list(filter(None, LabelList))\n    return LabelList\n\n\ndef Get_LabelEncodedArray(df_InputLabels, LabelList):\n    LabelArray = np.zeros((df_InputLabels.count(), len(LabelList)))\n    TagsArray = df_InputLabels.str.split(expand=True).to_numpy()\n\n    for i in range(TagsArray.shape[0]):\n        for j in range(TagsArray.shape[1]):\n            for k in range(len(LabelList)):\n                if(TagsArray[i][j]== LabelList[k]):\n                    LabelArray[i][k] = 1\n\n    return LabelArray\n\ndef OneHotToStringLabels(OneHotArray, LabelList, delimiter):\n    string_labels = \"\"\n    if(len(OneHotArray)!=len(LabelList)):\n        raise Exception(\"OneHotArray does not match LabelList len/size\")\n\n    for i in range(len(OneHotArray)):\n        if(OneHotArray[i] == 1.0):\n            if(string_labels == \"\"):\n                string_labels = LabelList[i]\n            else:\n                string_labels = string_labels+delimiter+LabelList[i]\n    return string_labels\n\ndef SplitData(df_Dataset, Ratio):\n\n    df_TrainData = pd.DataFrame(df_Dataset).sample(round(Ratio * df_Dataset['filename'].count()))\n\n    df_ValData = pd.DataFrame(df_Dataset)\n    condition = df_ValData['filename'].isin(df_TrainData['filename'])\n    df_ValData = df_ValData.drop(df_ValData[condition].index)\n\n    return df_TrainData, df_ValData","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:03.286736Z","iopub.execute_input":"2022-06-11T22:35:03.287056Z","iopub.status.idle":"2022-06-11T22:35:03.301992Z","shell.execute_reply.started":"2022-06-11T22:35:03.287014Z","shell.execute_reply":"2022-06-11T22:35:03.301128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Encoding labels:** One-Hot","metadata":{}},{"cell_type":"code","source":"source_path = \"../input/amazon-satellite/raw-data\"\nsource_path_Labels = os.path.join(source_path, 'train_v2.csv')\nsource_path_Images = os.path.join(source_path, 'train-jpg')\n\ndf_Raw = pd.read_csv(source_path_Labels)\nLabelList = Get_ListOfLabels(df_Raw.tags)\n\nGet_LabelEncodedArray(df_Raw.tags, LabelList)\ndf_Dataset = pd.DataFrame(Get_LabelEncodedArray(df_Raw.tags, LabelList), columns=LabelList)\ndf_Dataset['filename'] = df_Raw.image_name.to_list()\ndf_Dataset['filename'] = df_Dataset['filename']+'.jpg'\ndf_Dataset = df_Dataset.loc[: , ['filename']+LabelList]","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:03.303103Z","iopub.execute_input":"2022-06-11T22:35:03.30333Z","iopub.status.idle":"2022-06-11T22:35:09.664586Z","shell.execute_reply.started":"2022-06-11T22:35:03.303299Z","shell.execute_reply":"2022-06-11T22:35:09.663542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration\n- Finding correlation between classes/labels and mutual exclusivity","metadata":{}},{"cell_type":"code","source":"# Find labels with high correlation\ndf_corr = df_Dataset.corr()\nprint(df_corr[df_corr>0.3])","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.667058Z","iopub.execute_input":"2022-06-11T22:35:09.667301Z","iopub.status.idle":"2022-06-11T22:35:09.741762Z","shell.execute_reply.started":"2022-06-11T22:35:09.667271Z","shell.execute_reply":"2022-06-11T22:35:09.740675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find labels with low correlation\ndf_corr = df_Dataset.corr()\nprint(df_corr[df_corr<-0.2])","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.743264Z","iopub.execute_input":"2022-06-11T22:35:09.743498Z","iopub.status.idle":"2022-06-11T22:35:09.797749Z","shell.execute_reply.started":"2022-06-11T22:35:09.743465Z","shell.execute_reply":"2022-06-11T22:35:09.796873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify mutual exclusivity of 4 labels: clear, haze, partly_cloudy, cloudy\n\nprint('Images labelled as clear AND haze:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['haze']==1.0)]['filename'].count()))\nprint('Images labelled as clear AND partly_cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['partly_cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as clear AND cloudy:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as haze AND partly_cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['haze']==1.0) & (df_Dataset['partly_cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as haze AND cloudy:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['haze']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as partly_cloudy AND cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['partly_cloudy']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\n\nprint('\\nImages with any of these 4 labels:\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) | (df_Dataset['haze']==1.0) | (df_Dataset['partly_cloudy']==1.0) | (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images without any of these 4 labels:\\t'+str(df_Dataset.loc[~((df_Dataset['clear']==1.0) | (df_Dataset['haze']==1.0) | (df_Dataset['partly_cloudy']==1.0) | (df_Dataset['cloudy']==1.0))]['filename'].count()))\nprint('total number of images:\\t\\t\\t'+str(df_Raw.tags.count()))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.799358Z","iopub.execute_input":"2022-06-11T22:35:09.799864Z","iopub.status.idle":"2022-06-11T22:35:09.84678Z","shell.execute_reply.started":"2022-06-11T22:35:09.799817Z","shell.execute_reply":"2022-06-11T22:35:09.846095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verify mutual exclusivity of 4 labels: artisinal_mine and conventional_mine\n\nprint('Images labelled as artisinal_mine AND conventional_mine: '+str(df_Dataset.loc[(df_Dataset['artisinal_mine']==1.0) & (df_Dataset['conventional_mine']==1.0)]['filename'].count()))\nprint('Images labelled as artisinal_mine OR conventional_mine: '+str(df_Dataset.loc[(df_Dataset['artisinal_mine']==1.0) | (df_Dataset['conventional_mine']==1.0)]['filename'].count()))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.848332Z","iopub.execute_input":"2022-06-11T22:35:09.848806Z","iopub.status.idle":"2022-06-11T22:35:09.861556Z","shell.execute_reply.started":"2022-06-11T22:35:09.848762Z","shell.execute_reply":"2022-06-11T22:35:09.860609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation Generators\n\nNow that you know the images you are dealing with, it is time for you to code the generators that will fed these images to your Network. For this, complete the `train_val_generators` function below:\n\n**Important Note:** The images have a resolution of 256x256 but the `flow_from_dataframe` method you will use allows you to set a target resolution. Lower resolution may yield much quicker training times without compromising the accuracy!","metadata":{}},{"cell_type":"code","source":"def generate_generator_multiple(generator, directory, df1, df2, df3, df4, df5, batch_size, target_size):\n    genX1 = generator.flow_from_dataframe(dataframe = df1,\n                                          directory=directory,\n                                          x_col=df1.columns[0],\n                                          y_col=df1.columns[1:len(df1.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX2 = generator.flow_from_dataframe(dataframe = df2,\n                                          directory=directory,\n                                          x_col=df2.columns[0],\n                                          y_col=df2.columns[1:len(df2.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX3 = generator.flow_from_dataframe(dataframe = df3,\n                                          directory=directory,\n                                          x_col=df3.columns[0],\n                                          y_col=df3.columns[1:len(df3.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX4 = generator.flow_from_dataframe(dataframe = df4,\n                                          directory=directory,\n                                          x_col=df4.columns[0],\n                                          y_col=df4.columns[1:len(df4.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX5 = generator.flow_from_dataframe(dataframe = df5,\n                                          directory=directory,\n                                          x_col=df5.columns[0],\n                                          y_col=df5.columns[1:len(df5.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    for i in range(df1['filename'].count()):\n            X1i = genX1.next()\n            X2i = genX2.next()\n            X3i = genX3.next()\n            X4i = genX4.next()\n            X5i = genX5.next()\n            yield X1i[0],[X1i[1], X2i[1], X3i[1], X4i[1], X5i[1]]\n\n\n            \n            \n            \n# Get Data Generators\ndef train_val_generators(DIRECTORY, df_Train, df_Validation):\n    \n  # Instantiate the ImageDataGenerator class \n  # Don't forget to normalize pixel values and set arguments to augment the images \n  train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n                                     rotation_range=45,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     zoom_range=0.15,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\n# create generator\n  df_vis = df_Train.loc[:, ['filename', 'clear', 'haze', 'partly_cloudy', 'cloudy']]\n  df_hum = df_Train.loc[:, ['filename', 'agriculture', 'cultivation', 'habitation']]\n  df_rw  = df_Train.loc[:, ['filename', 'road', 'water']]\n  df_prim = df_Train.loc[:, ['filename', 'primary']]\n  df_rem = df_Train.loc[:, ['filename', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'conventional_mine', 'selective_logging', 'slash_burn']]\n\n  train_generator = generate_generator_multiple(train_datagen, DIRECTORY, df_vis, df_hum, df_rw, df_prim, df_rem, 32, (256, 256))\n    \n#   train_generator = train_datagen.flow_from_dataframe(dataframe=df_Train,\n#                                                       directory=DIRECTORY,\n#                                                       x_col=df_Train.columns[0],\n#                                                       y_col=df_Train.columns[1:len(df_Train.columns)],\n#                                                       batch_size=32, \n#                                                       class_mode='raw',\n#                                                       target_size=(256, 256))\n\n  # Instantiate the ImageDataGenerator class (set the rescale argument)\n  # Validation data not augmented\n  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n    \n  df_vis = df_ValData.loc[:, ['filename', 'clear', 'haze', 'partly_cloudy', 'cloudy']]\n  df_hum = df_ValData.loc[:, ['filename', 'agriculture', 'cultivation', 'habitation']]\n  df_rw  = df_ValData.loc[:, ['filename', 'road', 'water']]\n  df_prim = df_ValData.loc[:, ['filename', 'primary']]\n  df_rem = df_ValData.loc[:, ['filename', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'conventional_mine', 'selective_logging', 'slash_burn']]\n\n  validation_generator = generate_generator_multiple(validation_datagen, DIRECTORY, df_vis, df_hum, df_rw, df_prim, df_rem, 32, (256, 256))\n  \n#   flow_from_dataframe method\n#   validation_generator = validation_datagen.flow_from_dataframe(dataframe=df_Validation,\n#                                                                 directory=DIRECTORY,\n#                                                                 x_col=df_ValData.columns[0],\n#                                                                 y_col=df_ValData.columns[1:len(df_ValData.columns)],\n#                                                                 batch_size=32,\n#                                                                 class_mode='raw',\n#                                                                 target_size=(256, 256))\n  return train_generator, validation_generator","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.863701Z","iopub.execute_input":"2022-06-11T22:35:09.86413Z","iopub.status.idle":"2022-06-11T22:35:09.890299Z","shell.execute_reply.started":"2022-06-11T22:35:09.864082Z","shell.execute_reply":"2022-06-11T22:35:09.889499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data\nTrainToValidation_DataSize_Ratio = 0.8\ndf_TrainData, df_ValData = SplitData(df_Dataset, TrainToValidation_DataSize_Ratio)\n\n# Test Generators\ntrain_generator, validation_generator = train_val_generators(source_path_Images, df_TrainData, df_ValData)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.892552Z","iopub.execute_input":"2022-06-11T22:35:09.892894Z","iopub.status.idle":"2022-06-11T22:35:09.966101Z","shell.execute_reply.started":"2022-06-11T22:35:09.892849Z","shell.execute_reply":"2022-06-11T22:35:09.965121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Image Data Generator and Label Encoding\n- Verify if functions are working and visualize data","metadata":{}},{"cell_type":"code","source":"# data_index = 0\n\n# print(pd.DataFrame(np.array([LabelList, validation_generator.labels[data_index]]).transpose()).to_string(index=False))\n# print(\"\\nFile name:\\t\"+validation_generator.filenames[data_index])\n# print(\"Labels:\\t\\t\"+OneHotToStringLabels(validation_generator.labels[data_index], LabelList, ' ')+'\\n')\n\n# img = mpimg.imread(os.path.join(source_path_Images, validation_generator.filenames[data_index]))\n# img = img[:,:,:3]\n# plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.969452Z","iopub.execute_input":"2022-06-11T22:35:09.969814Z","iopub.status.idle":"2022-06-11T22:35:09.974073Z","shell.execute_reply.started":"2022-06-11T22:35:09.969767Z","shell.execute_reply":"2022-06-11T22:35:09.973196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Definition\n- Import InceptionV3 weights and define layers connected\n- Import VGG19 weights and define layers connected","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_addons as tfa\n\ndef create_model():\n    \n    Input = tf.keras.Input(shape=(256, 256, 3))\n    \n#     #Load ResNet50V2 Model\n    Model_1 = tf.keras.applications.ResNet50V2(input_tensor = Input, include_top = False, weights=\"imagenet\")\n    #Make all layers on ResNet50V2 trainable\n    for layer in Model_1.layers:\n        layer.trainable = True\n    x_Model_1 = Model_1(Input)\n    x_Model_1_Flat = tf.keras.layers.Flatten(name='Flatten_Model_1')(x_Model_1)\n    \n    \n#     #Load VGG19 Model\n    Model_2 = tf.keras.applications.VGG19(input_tensor = Input, include_top=False, weights=\"imagenet\")\n    #Make all layers on VGG19 trainable\n    for layer in Model_2.layers:\n            layer.trainable = True\n    x_Model_2 = Model_2(Input)\n    x_Model_2_Flat = tf.keras.layers.Flatten(name='Flatten_Model_2')(x_Model_2)\n    \n    \n    x_Top = tf.keras.layers.Concatenate(name='ConcatenateFlatten_Layer')([x_Model_1_Flat, x_Model_2_Flat])\n    x_Top = tf.keras.layers.Dense(2048, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    \n    #Define Visibility Branch\n    # x_vis[0] -> clear\n    # x_vis[1] -> haze\n    # x_vis[2] -> partly_cloudy\n    # x_vis[3] -> cloudy\n    x_vis = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    x_vis = tf.keras.layers.Dropout(0.4)(x_vis)\n    x_vis = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_vis)\n    x_vis = tf.keras.layers.Dropout(0.4)(x_vis)\n    x_vis = tf.keras.layers.Dense(256, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_vis)\n    x_vis = tf.keras.layers.Dropout(0.4)(x_vis)\n    x_vis = tf.keras.layers.Dense(4, activation='softmax', name = 'visibility', kernel_initializer = tf.keras.initializers.GlorotUniform())(x_vis)\n    \n    #Define Human Activity Branch\n    # x_hum[0] -> agriculture\n    # x_hum[1] -> cultivation\n    # x_hum[2] -> habitation\n    x_hum = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(256, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(128, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(3, activation='sigmoid', name='human_activity', kernel_initializer = tf.keras.initializers.GlorotUniform())(x_hum)\n    \n    #Define Track Branch (Road or Water)\n    # x_rw[0] -> road\n    # x_rw[1] -> water\n    x_rw = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(256, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(128, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(2, activation='sigmoid', name='road_water', kernel_initializer = tf.keras.initializers.GlorotUniform())(x_rw)\n    \n    #Define Primary Branch\n    #x_primary[0] -> primary\n    x_prim = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    x_prim = tf.keras.layers.Dropout(0.4)(x_prim)\n    x_prim = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_prim)\n    x_prim = tf.keras.layers.Dropout(0.4)(x_prim)\n    x_prim = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_prim)\n    x_prim = tf.keras.layers.Dropout(0.4)(x_prim)\n    x_prim = tf.keras.layers.Dense(256, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_prim)\n    x_prim = tf.keras.layers.Dropout(0.4)(x_prim)\n    x_prim = tf.keras.layers.Dense(1, activation='sigmoid', name='primary', kernel_initializer = tf.keras.initializers.GlorotUniform())(x_prim)\n    \n    \n    #Define Remaining Branch\n    #x_mine[0] -> artisinal_mine\n    # x_rem[1] -> bare_ground\n    # x_rem[2] -> blooming\n    # x_rem[3] -> blow_down\n    #x_mine[4] -> conventional_mine\n    # x_rem[5] -> selective_logging\n    # x_rem[6] -> slash_burn\n    x_rem = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_Top)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(512, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(256, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform())(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(7, activation='sigmoid', name='remaining', kernel_initializer = tf.keras.initializers.GlorotUniform())(x_rem)\n    \n    model = tf.keras.Model(inputs=Input, outputs=[x_vis, x_hum, x_rw, x_prim, x_rem])\n\n    model.compile(optimizer=Adam(lr=1e-4),\n                loss='binary_crossentropy',\n                metrics={\n                         'visibility': [tfa.metrics.FBetaScore(beta=2.0, num_classes=4 , average='micro', threshold=0.5)],\n                         'human_activity': [tfa.metrics.FBetaScore(beta=2.0, num_classes=3 , average='micro', threshold=0.5)],\n                         'road_water': [tfa.metrics.FBetaScore(beta=2.0, num_classes=2 , average='micro', threshold=0.5)],\n                         'primary': [tfa.metrics.FBetaScore(beta=2.0, num_classes=1 , average='micro', threshold=0.5)],\n                         'remaining': [tfa.metrics.FBetaScore(beta=2.0, num_classes=7 , average='micro', threshold=0.5)]\n                        }\n               ) \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:09.975855Z","iopub.execute_input":"2022-06-11T22:35:09.976363Z","iopub.status.idle":"2022-06-11T22:35:10.020636Z","shell.execute_reply.started":"2022-06-11T22:35:09.976329Z","shell.execute_reply":"2022-06-11T22:35:10.019831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callback to stop training","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        print(\"\\nReached FBeta Score = \"+str(statistics.harmonic_mean([logs.get('val_visibility_fbeta_score'), logs.get('val_human_activity_fbeta_score'), logs.get('val_road_water_fbeta_score'), logs.get('val_primary_fbeta_score')])))","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:10.0222Z","iopub.execute_input":"2022-06-11T22:35:10.02305Z","iopub.status.idle":"2022-06-11T22:35:10.036477Z","shell.execute_reply.started":"2022-06-11T22:35:10.022989Z","shell.execute_reply":"2022-06-11T22:35:10.035501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, History\n\nmodel = create_model()\nBATCH_SIZE = 32\n\ncallbacks = [History(),\n            myCallback(),\n            EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4, restore_best_weights=False),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=1, cooldown=0, min_lr=1e-7, verbose=1),\n            ModelCheckpoint(filepath='/kaggle/working/ResNet50VGG19.h5', monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False, mode='auto')]\n\nmodel_history = model.fit_generator(train_generator,\n                    steps_per_epoch = math.ceil(df_TrainData['filename'].count()/BATCH_SIZE),\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator,\n                    validation_steps = math.ceil(df_ValData['filename'].count()/BATCH_SIZE),\n                    callbacks=callbacks\n                   )\n\nhistory = model_history.history","metadata":{"execution":{"iopub.status.busy":"2022-06-11T22:35:10.038Z","iopub.execute_input":"2022-06-11T22:35:10.038499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save/Load Keras Model and History","metadata":{}},{"cell_type":"code","source":"# Save\nimport pickle\nfrom keras.models import load_model\nwith open(\"/kaggle/working/ResNet50VGG19.pkl\", 'wb') as f:\n    pickle.dump(history, f)\nmodel.save(\"/kaggle/working/ResNet50VGG19_EndTrain.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load\n# from tensorflow import keras\n# import pickle\n# model = keras.models.load_model(\"/kaggle/working/InceptionV3_Untrainable_V2.h5\")\n# with open(\"/kaggle/working/InceptionV3_Untrainable_V2.pkl\", 'rb') as f:\n#     history = pickle.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot History","metadata":{}},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nloss=history['loss']\nval_loss=history['val_loss']\n\nepochs=np.array(range(len(loss)))+1 # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, label=\"Training Loss\")\nplt.plot(epochs, val_loss, label=\"Validation Loss\")\nplt.title('Training and validation Loss')\nplt.xlim([0, 15])\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()\n\n#------------------------------------------------\n# Plot training and validation F Scores per epoch\n#------------------------------------------------\nplt.plot(epochs, history['visibility_fbeta_score'], label=\"Visibility - Train\")\nplt.plot(epochs, history['val_visibility_fbeta_score'], label=\"Visibility - Validation\")\nplt.plot(epochs, history['human_activity_fbeta_score'], label=\"Human Activity  - Train\")\nplt.plot(epochs, history['val_human_activity_fbeta_score'], label=\"Human Activity  - Validation\")\nplt.plot(epochs, history['road_water_fbeta_score'], label=\"Road-Water - Train\")\nplt.plot(epochs, history['val_road_water_fbeta_score'], label=\"Road-Water - Validation\")\nplt.plot(epochs, history['primary_fbeta_score'], label=\"Primary - Train\")\nplt.plot(epochs, history['val_primary_fbeta_score'], label=\"Primary - Validation\")\nplt.plot(epochs, history['remaining_fbeta_score'], label=\"Remaining - Train\")\nplt.plot(epochs, history['val_remaining_fbeta_score'], label=\"Remaining - Validation\")\nplt.title('F-Beta Score')\nplt.xlim([0, 15])\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Threshold optimization and Submission","metadata":{}},{"cell_type":"code","source":"import matplotlib.image as mpimg\nfrom IPython.display import clear_output\n\nfrom sklearn import metrics\nimport scipy\n\n\ndef GetOneHotFromPrediction(predictions):\n    OneHotPred = np.zeros((len(predictions[0]), 17))\n    for i in range(len(predictions[0])):\n        OneHotPred[i][0] = predictions[1][i][0]     #agriculture\n        OneHotPred[i][1] = predictions[4][i][0]     #artisinal_mine\n        OneHotPred[i][2] = predictions[4][i][1]     #bare_ground\n        OneHotPred[i][3] = predictions[4][i][2]     #blooming\n        OneHotPred[i][4] = predictions[4][i][3]     #blow_down\n        OneHotPred[i][5] = predictions[0][i][0]     #clear\n        OneHotPred[i][6] = predictions[0][i][3]     #cloudy\n        OneHotPred[i][7] = predictions[4][i][4]     #conventional_mine\n        OneHotPred[i][8] = predictions[1][i][1]     #cultivation\n        OneHotPred[i][9] = predictions[1][i][2]     #habitation\n        OneHotPred[i][10] = predictions[0][i][1]    #haze\n        OneHotPred[i][11] = predictions[0][i][2]    #partly_cloudy\n        OneHotPred[i][12] = predictions[3][i][0]    #primary\n        OneHotPred[i][13] = predictions[2][i][0]    #road\n        OneHotPred[i][14] = predictions[4][i][5]    #selective_logging\n        OneHotPred[i][15] = predictions[4][i][6]    #slash_burn\n        OneHotPred[i][16] = predictions[2][i][1]    #water\n    return OneHotPred\n\n\ndef GetFScore(threshold):\n    T_Val1 = np.zeros(True_Val1.shape)\n    T_Val2 = np.zeros(True_Val2.shape)\n    for i, row in enumerate(True_Val1):\n        for j, element in enumerate(row):\n            if(Pred_Val1[i][j] > threshold[j]):\n                T_Val1[i][j]=1\n            else:\n                T_Val1[i][j]=0\n    for i, row in enumerate(True_Val2):\n        for j, element in enumerate(row):\n            if(Pred_Val2[i][j] > threshold[j]):\n                T_Val2[i][j]=1\n            else:\n                T_Val2[i][j]=0\n    Fscore1 = sklearn.metrics.fbeta_score(y_true=True_Val1, y_pred=T_Val1, beta=2, average='micro')\n    Fscore2 = sklearn.metrics.fbeta_score(y_true=True_Val2, y_pred=T_Val2, beta=2, average='micro')\n    return ((Fscore1+Fscore2)/2.0)\n\n\ndef InsertLabels_Dataframe(df_Submission, predicted, threshold):\n    for i, ModelOutput in enumerate(predicted):\n        label = \"\"\n        if(ModelOutput[0] > threshold[0]):\n            label = label + \" agriculture\"\n        if(ModelOutput[1] > threshold[1]):\n            label = label + \" artisinal_mine\"\n        if(ModelOutput[2] > threshold[2]):\n            label = label + \" bare_ground\"\n        if(ModelOutput[3] > threshold[3]):\n            label = label + \" blooming\"\n        if(ModelOutput[4] > threshold[4]):\n            label = label + \" blow_down\"\n        if(ModelOutput[5] > threshold[5]):\n            label = label + \" clear\"\n        if(ModelOutput[6] > threshold[6]):\n            label = label + \" cloudy\"\n        if(ModelOutput[7] > threshold[7]):\n            label = label + \" conventional_mine\"\n        if(ModelOutput[8] > threshold[8]):\n            label = label + \" cultivation\"\n        if(ModelOutput[9] > threshold[9]):\n            label = label + \" habitation\"\n        if(ModelOutput[10] > threshold[10]):\n            label = label + \" haze\"\n        if(ModelOutput[11] > threshold[11]):\n            label = label + \" partly_cloudy\"\n        if(ModelOutput[12] > threshold[12]):\n            label = label + \" primary\"\n        if(ModelOutput[13] > threshold[13]):\n            label = label + \" road\"\n        if(ModelOutput[14] > threshold[14]):\n            label = label + \" selective_logging\"\n        if(ModelOutput[15] > threshold[15]):\n            label = label + \" slash_burn\"\n        if(ModelOutput[16] > threshold[16]):\n            label = label + \" water\"\n        df_Submission['tags'][i] = label","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FolderPath = '../input/amazon-satellite/raw-data/train-jpg'\ndf_Raw = pd.read_csv('../input/amazon-satellite/raw-data/train_v2.csv')\n\ndf_Dataset = pd.DataFrame(Get_LabelEncodedArray(df_Raw.tags, LabelList), columns=LabelList)\ndf_Dataset['filename'] = df_Raw.image_name.to_list()\ndf_Dataset['filename'] = df_Dataset['filename']+'.jpg'\ndf_Dataset = df_Dataset.loc[: , ['filename']+LabelList]\n\ndf_Val1, df_Val2 = SplitData(df_Dataset, Ratio=0.5)\n\nVal1_datagen = ImageDataGenerator(rescale=1.0/255.0)\nVal1_generator = Val1_datagen.flow_from_dataframe(dataframe=df_Val1,\n                                                                directory=FolderPath,\n                                                                x_col=df_Val1.columns[0],\n                                                                y_col=df_Val1.columns[1:len(df_Val1.columns)],\n                                                                batch_size=32,\n                                                                class_mode='raw',\n                                                                shuffle=False,\n                                                                target_size=(256, 256))\n\nVal2_datagen = ImageDataGenerator(rescale=1.0/255.0)\nVal2_generator = Val2_datagen.flow_from_dataframe(dataframe=df_Val2,\n                                                                directory=FolderPath,\n                                                                x_col=df_Val2.columns[0],\n                                                                y_col=df_Val2.columns[1:len(df_Val2.columns)],\n                                                                batch_size=32,\n                                                                class_mode='raw',\n                                                                shuffle=False,\n                                                                target_size=(256, 256))\n\nTrue_Val1 = np.array(df_Val1.loc[: , LabelList])\nTrue_Val2 = np.array(df_Val2.loc[: , LabelList])\n\nPred_Val1 = GetOneHotFromPrediction(model.predict(Val1_generator, verbose=1))\nPred_Val2 = GetOneHotFromPrediction(model.predict(Val2_generator, verbose=1))\n\ninitial_threshold = np.ones(17)*0.5\nprint(GetFScore(initial_threshold))\n\n# Threshold optimization\nlw = [0.0]*17\nup = [1.0]*17\nret = scipy.optimize.dual_annealing(lambda x: -GetFScore(x), bounds=list(zip(lw, up)))\nfinal_threshold = ret.x\noptimized_fscore = -ret.fun\nprint(final_threshold)\nprint(optimized_fscore)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Submission = pd.read_csv('../input/amazon-satellite/raw-data/sample_submission_v2/sample_submission_v2.csv')\ndf_Submission['image_name'] = df_Submission['image_name'] + '.jpg'\nTest_FolderPath = '../input/amazon-satellite/raw-data/test-jpg'\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_generator = validation_datagen.flow_from_dataframe(dataframe=df_Submission,\n                                                                directory=Test_FolderPath,\n                                                                x_col=df_Submission.columns[0],\n                                                                y_col=df_Submission.columns[1:len(df_Submission.columns)],\n                                                                batch_size=32,\n                                                                class_mode='raw',\n                                                                shuffle=False,\n                                                                target_size=(256, 256))\n\nRaw_Predictions = model.predict(validation_generator, verbose=1)\nOneHot_Predictions = GetOneHotFromPrediction(Raw_Predictions)\nInsertLabels_Dataframe(df_Submission, OneHot_Predictions, threshold=optimized_fscore)\n\ndf_Submission['image_name'] = df_Submission['image_name'].str.replace('.jpg', '')\ndf_Submission.to_csv('/kaggle/working/submission.csv', index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}