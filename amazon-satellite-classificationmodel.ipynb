{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datetime import datetime\nfrom datetime import timedelta\nimport os\nimport math\nimport statistics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom IPython.display import clear_output\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\nimport tensorflow_addons as tfa\n\n# tf.test.is_gpu_available()\n# tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:24.292826Z","iopub.execute_input":"2022-05-27T19:44:24.293459Z","iopub.status.idle":"2022-05-27T19:44:24.300486Z","shell.execute_reply.started":"2022-05-27T19:44:24.293399Z","shell.execute_reply":"2022-05-27T19:44:24.299670Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Def functions: One-Hot Encoding and Split Data (Dataframe)","metadata":{}},{"cell_type":"code","source":"def Get_ListOfLabels(df_InputLabels):\n    df_Tags = df_InputLabels.str.split(expand=True)\n    columns = len(df_Tags.columns)\n\n    for i in range(columns):\n        if i == 0:\n            df_aux = pd.DataFrame(df_Tags[0])\n        else:\n            df_aux = df_aux.append(pd.DataFrame(df_Tags[i].rename(index=0)))\n\n    LabelList = (df_aux.drop_duplicates().sort_values([0], ascending=[True]))[0].tolist()\n    LabelList = list(filter(None, LabelList))\n    return LabelList\n\n\ndef Get_LabelEncodedArray(df_InputLabels, LabelList):\n    LabelArray = np.zeros((df_InputLabels.count(), len(LabelList)))\n    TagsArray = df_InputLabels.str.split(expand=True).to_numpy()\n\n    for i in range(TagsArray.shape[0]):\n        for j in range(TagsArray.shape[1]):\n            for k in range(len(LabelList)):\n                if(TagsArray[i][j]== LabelList[k]):\n                    LabelArray[i][k] = 1\n\n    return LabelArray\n\ndef OneHotToStringLabels(OneHotArray, LabelList, delimiter):\n    string_labels = \"\"\n    if(len(OneHotArray)!=len(LabelList)):\n        raise Exception(\"OneHotArray does not match LabelList len/size\")\n\n    for i in range(len(OneHotArray)):\n        if(OneHotArray[i] == 1.0):\n            if(string_labels == \"\"):\n                string_labels = LabelList[i]\n            else:\n                string_labels = string_labels+delimiter+LabelList[i]\n    return string_labels\n\ndef SplitData(df_Dataset, Ratio):\n\n    df_TrainData = pd.DataFrame(df_Dataset).sample(round(Ratio * df_Dataset['filename'].count()))\n\n    df_ValData = pd.DataFrame(df_Dataset)\n    condition = df_ValData['filename'].isin(df_TrainData['filename'])\n    df_ValData = df_ValData.drop(df_ValData[condition].index)\n\n    return df_TrainData, df_ValData","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:24.326954Z","iopub.execute_input":"2022-05-27T19:44:24.327917Z","iopub.status.idle":"2022-05-27T19:44:24.403266Z","shell.execute_reply.started":"2022-05-27T19:44:24.327873Z","shell.execute_reply":"2022-05-27T19:44:24.402226Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### **Encoding labels:** One-Hot","metadata":{}},{"cell_type":"code","source":"source_path = \"../input/amazon-satellite/raw-data\"\nsource_path_Labels = os.path.join(source_path, 'train_v2.csv')\nsource_path_Images = os.path.join(source_path, 'train-jpg')\n\ndf_Raw = pd.read_csv(source_path_Labels)\nLabelList = Get_ListOfLabels(df_Raw.tags)\n\nGet_LabelEncodedArray(df_Raw.tags, LabelList)\ndf_Dataset = pd.DataFrame(Get_LabelEncodedArray(df_Raw.tags, LabelList), columns=LabelList)\ndf_Dataset['filename'] = df_Raw.image_name.to_list()\ndf_Dataset['filename'] = df_Dataset['filename']+'.jpg'\ndf_Dataset = df_Dataset.loc[: , ['filename']+LabelList]","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:24.405147Z","iopub.execute_input":"2022-05-27T19:44:24.406514Z","iopub.status.idle":"2022-05-27T19:44:31.654872Z","shell.execute_reply.started":"2022-05-27T19:44:24.406439Z","shell.execute_reply":"2022-05-27T19:44:31.653904Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration\n- Finding correlation between classes/labels and mutual exclusivity","metadata":{}},{"cell_type":"code","source":"# Find labels with high correlation\ndf_corr = df_Dataset.corr()\nprint(df_corr[df_corr>0.3])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.656068Z","iopub.execute_input":"2022-05-27T19:44:31.656351Z","iopub.status.idle":"2022-05-27T19:44:31.717758Z","shell.execute_reply.started":"2022-05-27T19:44:31.656322Z","shell.execute_reply":"2022-05-27T19:44:31.716933Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"                   agriculture  artisinal_mine  bare_ground  blooming  \\\nagriculture           1.000000             NaN          NaN       NaN   \nartisinal_mine             NaN             1.0          NaN       NaN   \nbare_ground                NaN             NaN          1.0       NaN   \nblooming                   NaN             NaN          NaN       1.0   \nblow_down                  NaN             NaN          NaN       NaN   \nclear                      NaN             NaN          NaN       NaN   \ncloudy                     NaN             NaN          NaN       NaN   \nconventional_mine          NaN             NaN          NaN       NaN   \ncultivation           0.344964             NaN          NaN       NaN   \nhabitation            0.303979             NaN          NaN       NaN   \nhaze                       NaN             NaN          NaN       NaN   \npartly_cloudy              NaN             NaN          NaN       NaN   \nprimary                    NaN             NaN          NaN       NaN   \nroad                  0.480930             NaN          NaN       NaN   \nselective_logging          NaN             NaN          NaN       NaN   \nslash_burn                 NaN             NaN          NaN       NaN   \nwater                      NaN             NaN          NaN       NaN   \n\n                   blow_down  clear  cloudy  conventional_mine  cultivation  \\\nagriculture              NaN    NaN     NaN                NaN     0.344964   \nartisinal_mine           NaN    NaN     NaN                NaN          NaN   \nbare_ground              NaN    NaN     NaN                NaN          NaN   \nblooming                 NaN    NaN     NaN                NaN          NaN   \nblow_down                1.0    NaN     NaN                NaN          NaN   \nclear                    NaN    1.0     NaN                NaN          NaN   \ncloudy                   NaN    NaN     1.0                NaN          NaN   \nconventional_mine        NaN    NaN     NaN                1.0          NaN   \ncultivation              NaN    NaN     NaN                NaN     1.000000   \nhabitation               NaN    NaN     NaN                NaN          NaN   \nhaze                     NaN    NaN     NaN                NaN          NaN   \npartly_cloudy            NaN    NaN     NaN                NaN          NaN   \nprimary                  NaN    NaN     NaN                NaN          NaN   \nroad                     NaN    NaN     NaN                NaN          NaN   \nselective_logging        NaN    NaN     NaN                NaN          NaN   \nslash_burn               NaN    NaN     NaN                NaN          NaN   \nwater                    NaN    NaN     NaN                NaN          NaN   \n\n                   habitation  haze  partly_cloudy  primary      road  \\\nagriculture          0.303979   NaN            NaN      NaN  0.480930   \nartisinal_mine            NaN   NaN            NaN      NaN       NaN   \nbare_ground               NaN   NaN            NaN      NaN       NaN   \nblooming                  NaN   NaN            NaN      NaN       NaN   \nblow_down                 NaN   NaN            NaN      NaN       NaN   \nclear                     NaN   NaN            NaN      NaN       NaN   \ncloudy                    NaN   NaN            NaN      NaN       NaN   \nconventional_mine         NaN   NaN            NaN      NaN       NaN   \ncultivation               NaN   NaN            NaN      NaN       NaN   \nhabitation           1.000000   NaN            NaN      NaN  0.443341   \nhaze                      NaN   1.0            NaN      NaN       NaN   \npartly_cloudy             NaN   NaN            1.0      NaN       NaN   \nprimary                   NaN   NaN            NaN      1.0       NaN   \nroad                 0.443341   NaN            NaN      NaN  1.000000   \nselective_logging         NaN   NaN            NaN      NaN       NaN   \nslash_burn                NaN   NaN            NaN      NaN       NaN   \nwater                     NaN   NaN            NaN      NaN       NaN   \n\n                   selective_logging  slash_burn  water  \nagriculture                      NaN         NaN    NaN  \nartisinal_mine                   NaN         NaN    NaN  \nbare_ground                      NaN         NaN    NaN  \nblooming                         NaN         NaN    NaN  \nblow_down                        NaN         NaN    NaN  \nclear                            NaN         NaN    NaN  \ncloudy                           NaN         NaN    NaN  \nconventional_mine                NaN         NaN    NaN  \ncultivation                      NaN         NaN    NaN  \nhabitation                       NaN         NaN    NaN  \nhaze                             NaN         NaN    NaN  \npartly_cloudy                    NaN         NaN    NaN  \nprimary                          NaN         NaN    NaN  \nroad                             NaN         NaN    NaN  \nselective_logging                1.0         NaN    NaN  \nslash_burn                       NaN         1.0    NaN  \nwater                            NaN         NaN    1.0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Find labels with low correlation\ndf_corr = df_Dataset.corr()\nprint(df_corr[df_corr<-0.2])","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.719440Z","iopub.execute_input":"2022-05-27T19:44:31.719669Z","iopub.status.idle":"2022-05-27T19:44:31.774491Z","shell.execute_reply.started":"2022-05-27T19:44:31.719644Z","shell.execute_reply":"2022-05-27T19:44:31.773554Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"                   agriculture  artisinal_mine  bare_ground  blooming  \\\nagriculture                NaN             NaN          NaN       NaN   \nartisinal_mine             NaN             NaN          NaN       NaN   \nbare_ground                NaN             NaN          NaN       NaN   \nblooming                   NaN             NaN          NaN       NaN   \nblow_down                  NaN             NaN          NaN       NaN   \nclear                      NaN             NaN          NaN       NaN   \ncloudy                     NaN             NaN          NaN       NaN   \nconventional_mine          NaN             NaN          NaN       NaN   \ncultivation                NaN             NaN          NaN       NaN   \nhabitation                 NaN             NaN          NaN       NaN   \nhaze                       NaN             NaN          NaN       NaN   \npartly_cloudy              NaN             NaN          NaN       NaN   \nprimary                    NaN             NaN          NaN       NaN   \nroad                       NaN             NaN          NaN       NaN   \nselective_logging          NaN             NaN          NaN       NaN   \nslash_burn                 NaN             NaN          NaN       NaN   \nwater                      NaN             NaN          NaN       NaN   \n\n                   blow_down     clear    cloudy  conventional_mine  \\\nagriculture              NaN       NaN       NaN                NaN   \nartisinal_mine           NaN       NaN       NaN                NaN   \nbare_ground              NaN       NaN       NaN                NaN   \nblooming                 NaN       NaN       NaN                NaN   \nblow_down                NaN       NaN       NaN                NaN   \nclear                    NaN       NaN -0.358343                NaN   \ncloudy                   NaN -0.358343       NaN                NaN   \nconventional_mine        NaN       NaN       NaN                NaN   \ncultivation              NaN       NaN       NaN                NaN   \nhabitation               NaN       NaN       NaN                NaN   \nhaze                     NaN -0.410428       NaN                NaN   \npartly_cloudy            NaN -0.718208       NaN                NaN   \nprimary                  NaN       NaN -0.829594                NaN   \nroad                     NaN       NaN       NaN                NaN   \nselective_logging        NaN       NaN       NaN                NaN   \nslash_burn               NaN       NaN       NaN                NaN   \nwater                    NaN       NaN       NaN                NaN   \n\n                   cultivation  habitation      haze  partly_cloudy   primary  \\\nagriculture                NaN         NaN       NaN            NaN       NaN   \nartisinal_mine             NaN         NaN       NaN            NaN       NaN   \nbare_ground                NaN         NaN       NaN            NaN       NaN   \nblooming                   NaN         NaN       NaN            NaN       NaN   \nblow_down                  NaN         NaN       NaN            NaN       NaN   \nclear                      NaN         NaN -0.410428      -0.718208       NaN   \ncloudy                     NaN         NaN       NaN            NaN -0.829594   \nconventional_mine          NaN         NaN       NaN            NaN       NaN   \ncultivation                NaN         NaN       NaN            NaN       NaN   \nhabitation                 NaN         NaN       NaN            NaN       NaN   \nhaze                       NaN         NaN       NaN            NaN       NaN   \npartly_cloudy              NaN         NaN       NaN            NaN       NaN   \nprimary                    NaN         NaN       NaN            NaN       NaN   \nroad                       NaN         NaN       NaN            NaN       NaN   \nselective_logging          NaN         NaN       NaN            NaN       NaN   \nslash_burn                 NaN         NaN       NaN            NaN       NaN   \nwater                      NaN         NaN       NaN            NaN       NaN   \n\n                   road  selective_logging  slash_burn  water  \nagriculture         NaN                NaN         NaN    NaN  \nartisinal_mine      NaN                NaN         NaN    NaN  \nbare_ground         NaN                NaN         NaN    NaN  \nblooming            NaN                NaN         NaN    NaN  \nblow_down           NaN                NaN         NaN    NaN  \nclear               NaN                NaN         NaN    NaN  \ncloudy              NaN                NaN         NaN    NaN  \nconventional_mine   NaN                NaN         NaN    NaN  \ncultivation         NaN                NaN         NaN    NaN  \nhabitation          NaN                NaN         NaN    NaN  \nhaze                NaN                NaN         NaN    NaN  \npartly_cloudy       NaN                NaN         NaN    NaN  \nprimary             NaN                NaN         NaN    NaN  \nroad                NaN                NaN         NaN    NaN  \nselective_logging   NaN                NaN         NaN    NaN  \nslash_burn          NaN                NaN         NaN    NaN  \nwater               NaN                NaN         NaN    NaN  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Verify mutual exclusivity of 4 labels: clear, haze, partly_cloudy, cloudy\n\nprint('Images labelled as clear AND haze:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['haze']==1.0)]['filename'].count()))\nprint('Images labelled as clear AND partly_cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['partly_cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as clear AND cloudy:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as haze AND partly_cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['haze']==1.0) & (df_Dataset['partly_cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as haze AND cloudy:\\t\\t\\t'+str(df_Dataset.loc[(df_Dataset['haze']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images labelled as partly_cloudy AND cloudy:\\t\\t'+str(df_Dataset.loc[(df_Dataset['partly_cloudy']==1.0) & (df_Dataset['cloudy']==1.0)]['filename'].count()))\n\nprint('\\nImages with any of these 4 labels:\\t'+str(df_Dataset.loc[(df_Dataset['clear']==1.0) | (df_Dataset['haze']==1.0) | (df_Dataset['partly_cloudy']==1.0) | (df_Dataset['cloudy']==1.0)]['filename'].count()))\nprint('Images without any of these 4 labels:\\t'+str(df_Dataset.loc[~((df_Dataset['clear']==1.0) | (df_Dataset['haze']==1.0) | (df_Dataset['partly_cloudy']==1.0) | (df_Dataset['cloudy']==1.0))]['filename'].count()))\nprint('total number of images:\\t\\t\\t'+str(df_Raw.tags.count()))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.776017Z","iopub.execute_input":"2022-05-27T19:44:31.776887Z","iopub.status.idle":"2022-05-27T19:44:31.820879Z","shell.execute_reply.started":"2022-05-27T19:44:31.776843Z","shell.execute_reply":"2022-05-27T19:44:31.819983Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Images labelled as clear AND haze:\t\t\t0\nImages labelled as clear AND partly_cloudy:\t\t0\nImages labelled as clear AND cloudy:\t\t\t0\nImages labelled as haze AND partly_cloudy:\t\t0\nImages labelled as haze AND cloudy:\t\t\t0\nImages labelled as partly_cloudy AND cloudy:\t\t0\n\nImages with any of these 4 labels:\t40478\nImages without any of these 4 labels:\t1\ntotal number of images:\t\t\t40479\n","output_type":"stream"}]},{"cell_type":"code","source":"# Verify mutual exclusivity of 4 labels: artisinal_mine and conventional_mine\n\nprint('Images labelled as artisinal_mine AND conventional_mine: '+str(df_Dataset.loc[(df_Dataset['artisinal_mine']==1.0) & (df_Dataset['conventional_mine']==1.0)]['filename'].count()))\nprint('Images labelled as artisinal_mine OR conventional_mine: '+str(df_Dataset.loc[(df_Dataset['artisinal_mine']==1.0) | (df_Dataset['conventional_mine']==1.0)]['filename'].count()))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.822383Z","iopub.execute_input":"2022-05-27T19:44:31.822658Z","iopub.status.idle":"2022-05-27T19:44:31.835072Z","shell.execute_reply.started":"2022-05-27T19:44:31.822624Z","shell.execute_reply":"2022-05-27T19:44:31.833946Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Images labelled as artisinal_mine AND conventional_mine: 4\nImages labelled as artisinal_mine OR conventional_mine: 435\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training and Validation Generators\n\nNow that you know the images you are dealing with, it is time for you to code the generators that will fed these images to your Network. For this, complete the `train_val_generators` function below:\n\n**Important Note:** The images have a resolution of 256x256 but the `flow_from_dataframe` method you will use allows you to set a target resolution. Lower resolution may yield much quicker training times without compromising the accuracy!","metadata":{}},{"cell_type":"code","source":"def generate_generator_multiple(generator, directory, df1, df2, df3, df4, df5, batch_size, target_size):\n    genX1 = generator.flow_from_dataframe(dataframe = df1,\n                                          directory=directory,\n                                          x_col=df1.columns[0],\n                                          y_col=df1.columns[1:len(df1.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX2 = generator.flow_from_dataframe(dataframe = df2,\n                                          directory=directory,\n                                          x_col=df2.columns[0],\n                                          y_col=df2.columns[1:len(df2.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX3 = generator.flow_from_dataframe(dataframe = df3,\n                                          directory=directory,\n                                          x_col=df3.columns[0],\n                                          y_col=df3.columns[1:len(df3.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX4 = generator.flow_from_dataframe(dataframe = df4,\n                                          directory=directory,\n                                          x_col=df4.columns[0],\n                                          y_col=df4.columns[1:len(df4.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    genX5 = generator.flow_from_dataframe(dataframe = df5,\n                                          directory=directory,\n                                          x_col=df5.columns[0],\n                                          y_col=df5.columns[1:len(df5.columns)],\n                                          target_size = target_size,\n                                          class_mode = 'raw',\n                                          batch_size = batch_size,\n                                          shuffle=False, \n                                          seed=7)\n    \n    for i in range(df1['filename'].count()):\n            X1i = genX1.next()\n            X2i = genX2.next()\n            X3i = genX3.next()\n            X4i = genX4.next()\n            X5i = genX5.next()\n            yield X1i[0],[X1i[1], X2i[1], X3i[1], X4i[1], X5i[1]]\n\n\n            \n            \n            \n# Get Data Generators\ndef train_val_generators(DIRECTORY, df_Train, df_Validation):\n    \n  # Instantiate the ImageDataGenerator class \n  # Don't forget to normalize pixel values and set arguments to augment the images \n  train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n                                     rotation_range=20,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\n# create generator\n  df_vis = df_Train.loc[:, ['filename', 'clear', 'haze', 'partly_cloudy', 'cloudy']]\n  df_hum = df_Train.loc[:, ['filename', 'agriculture', 'cultivation', 'habitation']]\n  df_rw  = df_Train.loc[:, ['filename', 'road', 'water']]\n  df_prim = df_Train.loc[:, ['filename', 'primary']]\n  df_rem = df_Train.loc[:, ['filename', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'conventional_mine', 'selective_logging', 'slash_burn']]\n\n  train_generator = generate_generator_multiple(train_datagen, DIRECTORY, df_vis, df_hum, df_rw, df_prim, df_rem, 32, (256, 256))\n    \n#   train_generator = train_datagen.flow_from_dataframe(dataframe=df_Train,\n#                                                       directory=DIRECTORY,\n#                                                       x_col=df_Train.columns[0],\n#                                                       y_col=df_Train.columns[1:len(df_Train.columns)],\n#                                                       batch_size=32, \n#                                                       class_mode='raw',\n#                                                       target_size=(256, 256))\n\n  # Instantiate the ImageDataGenerator class (set the rescale argument)\n  # Validation data not augmented\n  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n    \n  df_vis = df_ValData.loc[:, ['filename', 'clear', 'haze', 'partly_cloudy', 'cloudy']]\n  df_hum = df_ValData.loc[:, ['filename', 'agriculture', 'cultivation', 'habitation']]\n  df_rw  = df_ValData.loc[:, ['filename', 'road', 'water']]\n  df_prim = df_ValData.loc[:, ['filename', 'primary']]\n  df_rem = df_ValData.loc[:, ['filename', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'conventional_mine', 'selective_logging', 'slash_burn']]\n\n  validation_generator = generate_generator_multiple(validation_datagen, DIRECTORY, df_vis, df_hum, df_rw, df_prim, df_rem, 32, (256, 256))\n  \n#   flow_from_dataframe method\n#   validation_generator = validation_datagen.flow_from_dataframe(dataframe=df_Validation,\n#                                                                 directory=DIRECTORY,\n#                                                                 x_col=df_ValData.columns[0],\n#                                                                 y_col=df_ValData.columns[1:len(df_ValData.columns)],\n#                                                                 batch_size=32,\n#                                                                 class_mode='raw',\n#                                                                 target_size=(256, 256))\n  return train_generator, validation_generator","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.836850Z","iopub.execute_input":"2022-05-27T19:44:31.837318Z","iopub.status.idle":"2022-05-27T19:44:31.863229Z","shell.execute_reply.started":"2022-05-27T19:44:31.837256Z","shell.execute_reply":"2022-05-27T19:44:31.862107Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Split Data\nTrainToValidation_DataSize_Ratio = 0.6\ndf_TrainData, df_ValData = SplitData(df_Dataset, TrainToValidation_DataSize_Ratio)\n\n# Test Generators\ntrain_generator, validation_generator = train_val_generators(source_path_Images, df_TrainData, df_ValData)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.864600Z","iopub.execute_input":"2022-05-27T19:44:31.864944Z","iopub.status.idle":"2022-05-27T19:44:31.937918Z","shell.execute_reply.started":"2022-05-27T19:44:31.864916Z","shell.execute_reply":"2022-05-27T19:44:31.936879Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Test Image Data Generator and Label Encoding\n- Verify if functions are working and visualize data","metadata":{}},{"cell_type":"code","source":"# data_index = 0\n\n# print(pd.DataFrame(np.array([LabelList, validation_generator.labels[data_index]]).transpose()).to_string(index=False))\n# print(\"\\nFile name:\\t\"+validation_generator.filenames[data_index])\n# print(\"Labels:\\t\\t\"+OneHotToStringLabels(validation_generator.labels[data_index], LabelList, ' ')+'\\n')\n\n# img = mpimg.imread(os.path.join(source_path_Images, validation_generator.filenames[data_index]))\n# img = img[:,:,:3]\n# plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:31.939728Z","iopub.execute_input":"2022-05-27T19:44:31.940071Z","iopub.status.idle":"2022-05-27T19:44:31.944713Z","shell.execute_reply.started":"2022-05-27T19:44:31.940023Z","shell.execute_reply":"2022-05-27T19:44:31.943767Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Model Definition\n- Import InceptionV3 weights and define layers connected\n- Import VGG19 weights and define layers connected","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nimport tensorflow_addons as tfa\n\ndef create_model():\n    \n    Input = tf.keras.Input(shape=(256, 256, 3))\n    \n#     #Load InceptionV3 Model\n    Model_1 = tf.keras.applications.InceptionV3(input_tensor = Input, include_top = False, weights=\"imagenet\", classes=17)\n    #Make all layers on InceptionV3 untrainable\n    for layer in Model_1.layers:\n        layer.trainable = False\n    x_Model_1 = Model_1(Input)\n    x_Model_1_Flat = tf.keras.layers.Flatten(name='Flatten_Model_1')(x_Model_1)\n    \n    \n#     #Load VGG19 Model\n    Model_2 = tf.keras.applications.ResNet50V2(input_tensor = Input, include_top=False, weights=\"imagenet\", classes=17)\n    for layer in Model_2.layers:\n            layer.trainable = False\n    x_Model_2 = Model_2(Input)\n    x_Model_2_Flat = tf.keras.layers.Flatten(name='Flatten_Model_2')(x_Model_2)\n    \n    \n    x_Top = tf.keras.layers.Concatenate(name='ConcatenateFlatten_Layer')([x_Model_1_Flat, x_Model_2_Flat])\n    \n    #Define Visibility Branch\n    # x_vis[0] -> clear\n    # x_vis[1] -> haze\n    # x_vis[2] -> partly_cloudy\n    # x_vis[3] -> cloudy\n    x_vis = tf.keras.layers.Dense(512, activation='relu')(x_Top)\n    x_vis = tf.keras.layers.BatchNormalization()(x_vis)\n    x_vis = tf.keras.layers.Dropout(0.2)(x_vis)\n    x_vis = tf.keras.layers.Dense(256, activation='relu')(x_vis)\n    x_vis = tf.keras.layers.BatchNormalization()(x_vis)\n    x_vis = tf.keras.layers.Dropout(0.4)(x_vis)\n    x_vis = tf.keras.layers.Dense(4, activation='softmax', name = 'visibility')(x_vis)\n    \n    #Define Human Activity Branch\n    # x_hum[0] -> agriculture\n    # x_hum[1] -> cultivation\n    # x_hum[2] -> habitation\n    x_hum = tf.keras.layers.Dense(512, activation='relu')(x_Top)\n    x_hum = tf.keras.layers.BatchNormalization()(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.2)(x_hum)\n    x_hum = tf.keras.layers.Dense(512, activation='relu')(x_hum)\n    x_hum = tf.keras.layers.BatchNormalization()(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.2)(x_hum)\n    x_hum = tf.keras.layers.Dense(256, activation='relu')(x_hum)\n    x_hum = tf.keras.layers.BatchNormalization()(x_hum)\n    x_hum = tf.keras.layers.Dropout(0.4)(x_hum)\n    x_hum = tf.keras.layers.Dense(3, activation='sigmoid', name='human_activity')(x_hum)\n    \n    #Define Track Branch (Road or Water)\n    # x_rw[0] -> road\n    # x_rw[1] -> water\n    x_rw = tf.keras.layers.Dense(512, activation='relu')(x_Top)\n    x_rw = tf.keras.layers.BatchNormalization()(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.2)(x_rw)\n    x_rw = tf.keras.layers.Dense(512, activation='relu')(x_rw)\n    x_rw = tf.keras.layers.BatchNormalization()(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.2)(x_rw)\n    x_rw = tf.keras.layers.Dense(256, activation='relu')(x_rw)\n    x_rw = tf.keras.layers.BatchNormalization()(x_rw)\n    x_rw = tf.keras.layers.Dropout(0.4)(x_rw)\n    x_rw = tf.keras.layers.Dense(2, activation='sigmoid', name='road_water')(x_rw)\n    \n    #Define Primary Branch\n    #x_primary[0] -> primary\n    x_prim = tf.keras.layers.Dense(512, activation='relu')(x_Top)\n    x_prim = tf.keras.layers.BatchNormalization()(x_prim)\n    x_prim = tf.keras.layers.Dropout(0.2)(x_prim)\n    x_prim = tf.keras.layers.Dense(256, activation='relu')(x_prim)\n    x_prim = tf.keras.layers.BatchNormalization()(x_prim)\n    x_prim = tf.keras.layers.Dropout(0.4)(x_prim)\n    x_prim = tf.keras.layers.Dense(1, activation='sigmoid', name='primary')(x_prim)\n    \n    \n    #Define Remaining Branch\n    #x_mine[0] -> artisinal_mine\n    # x_rem[1] -> bare_ground\n    # x_rem[2] -> blooming\n    # x_rem[3] -> blow_down\n    #x_mine[4] -> conventional_mine\n    # x_rem[5] -> selective_logging\n    # x_rem[6] -> slash_burn\n    x_rem = tf.keras.layers.Dense(512, activation='relu')(x_Top)\n    x_rem = tf.keras.layers.BatchNormalization()(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.2)(x_rem)\n    x_rem = tf.keras.layers.Dense(512, activation='relu')(x_rem)\n    x_rem = tf.keras.layers.BatchNormalization()(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(512, activation='relu')(x_rem)\n    x_rem = tf.keras.layers.BatchNormalization()(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(256, activation='relu')(x_rem)\n    x_rem = tf.keras.layers.BatchNormalization()(x_rem)\n    x_rem = tf.keras.layers.Dropout(0.4)(x_rem)\n    x_rem = tf.keras.layers.Dense(7, activation='sigmoid', name='remaining')(x_rem)\n    \n    model = tf.keras.Model(inputs=Input, outputs=[x_vis, x_hum, x_rw, x_prim, x_rem])\n\n    model.compile(optimizer=RMSprop(learning_rate=0.004),\n                loss='binary_crossentropy',\n                metrics={\n                         'visibility': [tfa.metrics.FBetaScore(beta=2.0, num_classes=4 , average='micro', threshold=0.5)],\n                         'human_activity': [tfa.metrics.FBetaScore(beta=2.0, num_classes=3 , average='micro', threshold=0.5)],\n                         'road_water': [tfa.metrics.FBetaScore(beta=2.0, num_classes=2 , average='micro', threshold=0.5)],\n                         'primary': [tfa.metrics.FBetaScore(beta=2.0, num_classes=1 , average='micro', threshold=0.5)],\n                         'remaining': [tfa.metrics.FBetaScore(beta=2.0, num_classes=7 , average='micro', threshold=0.5)]\n                        }\n               ) \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:46:20.089272Z","iopub.execute_input":"2022-05-27T19:46:20.089579Z","iopub.status.idle":"2022-05-27T19:46:20.127726Z","shell.execute_reply.started":"2022-05-27T19:46:20.089550Z","shell.execute_reply":"2022-05-27T19:46:20.127009Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Callback to stop training","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(statistics.harmonic_mean([logs.get('val_visibility_fbeta_score'), logs.get('val_human_activity_fbeta_score'), logs.get('val_remaining_fbeta_score'), logs.get('val_road_water_fbeta_score')])>0.90):\n        print(\"\\nReached FBeta Score = \"+str(statistics.harmonic_mean([logs.get('val_visibility_fbeta_score'), logs.get('val_human_activity_fbeta_score'), logs.get('val_remaining_fbeta_score'), logs.get('val_road_water_fbeta_score')])))\n#       self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:46:23.355051Z","iopub.execute_input":"2022-05-27T19:46:23.355913Z","iopub.status.idle":"2022-05-27T19:46:23.363624Z","shell.execute_reply.started":"2022-05-27T19:46:23.355862Z","shell.execute_reply":"2022-05-27T19:46:23.362798Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"model = create_model()\n\nBATCH_SIZE = 32\n\nmodel_history = model.fit_generator(train_generator,\n                    steps_per_epoch = math.ceil(df_TrainData['filename'].count()/BATCH_SIZE),\n                    epochs=15,\n                    verbose=1,\n                    validation_data=validation_generator,\n                    validation_steps = math.ceil(df_ValData['filename'].count()/BATCH_SIZE),\n                    callbacks=myCallback()\n                   )\n\nhistory = model_history.history","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:46:24.931783Z","iopub.execute_input":"2022-05-27T19:46:24.932381Z","iopub.status.idle":"2022-05-27T19:49:25.819918Z","shell.execute_reply.started":"2022-05-27T19:46:24.932333Z","shell.execute_reply":"2022-05-27T19:49:25.818415Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n94674944/94668760 [==============================] - 1s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"Found 24287 validated image filenames.\nFound 24287 validated image filenames.\nFound 24287 validated image filenames.\nFound 24287 validated image filenames.\nFound 24287 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"2022-05-27 19:48:03.905030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2022-05-27 19:48:03.912043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n  5/759 [..............................] - ETA: 2:13:45 - loss: 5.7190 - visibility_loss: 1.0810 - human_activity_loss: 1.3344 - road_water_loss: 1.1279 - primary_loss: 1.1820 - remaining_loss: 0.9937 - visibility_fbeta_score: 0.2978 - human_activity_fbeta_score: 0.4707 - road_water_fbeta_score: 0.4938 - primary_fbeta_score: 0.6911 - remaining_fbeta_score: 0.0259 ","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_45/106521483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ValData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                    )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## Save/Load Keras Model and History","metadata":{}},{"cell_type":"code","source":"# Save\nimport pickle\nfrom keras.models import load_model\nwith open(\"/kaggle/working/InceptionNVGG19_Untrainable_V2.pkl\", 'wb') as f:\n    pickle.dump(history, f)\nmodel.save(\"/kaggle/working/InceptionNVGG19_Untrainable_V2.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:34.597416Z","iopub.status.idle":"2022-05-27T19:44:34.597786Z","shell.execute_reply.started":"2022-05-27T19:44:34.597590Z","shell.execute_reply":"2022-05-27T19:44:34.597620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load\n# from tensorflow import keras\n# import pickle\n# model = keras.models.load_model(\"/kaggle/working/InceptionV3_Untrainable_V2.h5\")\n# with open(\"/kaggle/working/InceptionV3_Untrainable_V2.pkl\", 'rb') as f:\n#     history = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:34.600240Z","iopub.status.idle":"2022-05-27T19:44:34.600755Z","shell.execute_reply.started":"2022-05-27T19:44:34.600479Z","shell.execute_reply":"2022-05-27T19:44:34.600506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot History","metadata":{}},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nloss=history['loss']\nval_loss=history['val_loss']\n\nepochs=np.array(range(len(loss)))+1 # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, label=\"Training Loss\")\nplt.plot(epochs, val_loss, label=\"Validation Loss\")\nplt.title('Training and validation Loss')\nplt.xlim([0, 15])\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()\n\n#------------------------------------------------\n# Plot training and validation F Scores per epoch\n#------------------------------------------------\nplt.plot(epochs, history['visibility_fbeta_score'], label=\"Visibility - Train\")\nplt.plot(epochs, history['val_visibility_fbeta_score'], label=\"Visibility - Validation\")\nplt.plot(epochs, history['human_activity_fbeta_score'], label=\"Human Activity  - Train\")\nplt.plot(epochs, history['val_human_activity_fbeta_score'], label=\"Human Activity  - Validation\")\nplt.plot(epochs, history['road_water_fbeta_score'], label=\"Road-Water - Train\")\nplt.plot(epochs, history['val_road_water_fbeta_score'], label=\"Road-Water - Validation\")\nplt.plot(epochs, history['primary_fbeta_score'], label=\"Primary - Train\")\nplt.plot(epochs, history['val_primary_fbeta_score'], label=\"Primary - Validation\")\nplt.plot(epochs, history['remaining_fbeta_score'], label=\"Remaining - Train\")\nplt.plot(epochs, history['val_remaining_fbeta_score'], label=\"Remaining - Validation\")\nplt.title('F-Beta Score')\nplt.xlim([0, 15])\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:34.603073Z","iopub.status.idle":"2022-05-27T19:44:34.603949Z","shell.execute_reply.started":"2022-05-27T19:44:34.603638Z","shell.execute_reply":"2022-05-27T19:44:34.603668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"import matplotlib.image as mpimg\nfrom IPython.display import clear_output\n\ndef GetPredictions(df_Submission, ImageFolderPath):\n\n    start_time = datetime.now()\n    iteration_time = start_time\n    df_Submission.image_name = df_Submission.image_name+'.jpg'\n\n    predicted = np.array([np.zeros(4), np.zeros(3), np.zeros(2), np.zeros(2), np.zeros(6)], dtype=object)\n    predicted = [predicted]*df_Submission.image_name.count()\n\n    for i, row in enumerate(df_Submission.to_numpy()):\n        img = mpimg.imread(os.path.join(ImageFolderPath, row[0]))\n        img = img[:,:,:3]\n        img = np.array([img])\n        predicted[i] = model.predict(img)\n        iteration_elapsed = datetime.now()-iteration_time\n        if(iteration_elapsed.total_seconds()>5.00):\n            iteration_time = datetime.now()\n            elapsed_time = (datetime.now()-start_time)\n            estimate_to_completion = (elapsed_time/i)*(df_Submission.count()[0]-i)\n            clear_output(wait=True)\n            print('Completed\\t\\t\\t', \"{:.2f}\".format(100*i/df_Submission.image_name.count()),'%')\n            print('Elapsed time:\\t\\t', elapsed_time)\n            print('Estimate to completion:\\t', estimate_to_completion)\n\n    clear_output(wait=True)\n    print('completed 100 %')\n    elapsed_time = (datetime.now()-start_time)\n    print('Elapsed time: ', elapsed_time)\n    return predicted\n\ndef GetPedictGeneratorOutput(prediction, index):\n    return [predictions[0][index], predictions[1][index], predictions[2][index], predictions[3][index], predictions[4][index]]\n\ndef GetLabelsFromPrediction(ModelOutput, threshold):\n    label = \"\"\n    if(ModelOutput[1][0] > threshold):\n        label = label + \" agriculture\"\n    if(ModelOutput[4][0] > threshold):\n        label = label + \" artisinal_mine\"\n    if(ModelOutput[4][1] > threshold):\n        label = label + \" bare_ground\"\n    if(ModelOutput[4][2] > threshold):\n        label = label + \" blooming\"\n    if(ModelOutput[4][3] > threshold):\n        label = label + \" blow_down\"\n    if(ModelOutput[0][0] > threshold):\n        label = label + \" clear\"\n    if(ModelOutput[0][3] > threshold):\n        label = label + \" cloudy\"\n    if(ModelOutput[4][4] > threshold):\n        label = label + \" conventional_mine\"\n    if(ModelOutput[1][1] > threshold):\n        label = label + \" cultivation\"\n    if(ModelOutput[1][2] > threshold):\n        label = label + \" habitation\"\n    if(ModelOutput[0][1] > threshold):\n        label = label + \" haze\"\n    if(ModelOutput[0][2] > threshold):\n        label = label + \" partly_cloudy\"\n    if(ModelOutput[3][0] > threshold):\n        label = label + \" primary\"\n    if(ModelOutput[2][0] > threshold):\n        label = label + \" road\"\n    if(ModelOutput[4][5] > threshold):\n        label = label + \" selective_logging\"\n    if(ModelOutput[4][6] > threshold):\n        label = label + \" slash_burn\"\n    if(ModelOutput[2][1] > threshold):\n        label = label + \" water\"\n    return label.lstrip()\n\n\ndef InsertLabels_Dataframe(df_Submission, predicted, threshold):\n    pred = []\n    for i in range(len(predicted[0])):\n        pred.append([])\n        pred[i] = [predicted[0][i], predicted[1][i], predicted[2][i], predicted[3][i], predicted[4][i]]\n    for i, ModelOutput in enumerate(pred):\n        df_Submission['tags'][i]=GetLabelsFromPrediction(ModelOutput, threshold)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:34.605626Z","iopub.status.idle":"2022-05-27T19:44:34.606460Z","shell.execute_reply.started":"2022-05-27T19:44:34.606134Z","shell.execute_reply":"2022-05-27T19:44:34.606163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Submission = pd.read_csv('../input/amazon-satellite/raw-data/sample_submission_v2/sample_submission_v2.csv')\nTest_FolderPath = '../input/amazon-satellite/raw-data/test-jpg'\n\ndf_Submission['image_name'] = df_Submission['image_name'] + '.jpg'\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255.0)\nvalidation_generator = validation_datagen.flow_from_dataframe(dataframe=df_Submission,\n                                                                directory=Test_FolderPath,\n                                                                x_col=df_Submission.columns[0],\n                                                                y_col=df_Submission.columns[1:len(df_Submission.columns)],\n                                                                batch_size=32,\n                                                                class_mode='raw',\n                                                                shuffle=False,\n                                                                target_size=(256, 256))\n\npredictions = model.predict(validation_generator, verbose=1)\nInsertLabels_Dataframe(df_Submission, predictions, threshold=0.5)\n\ndf_Submission['image_name'] = df_Submission['image_name'].str.replace('.jpg', '')\ndf_Submission.to_csv('/kaggle/working/submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T19:44:34.608070Z","iopub.status.idle":"2022-05-27T19:44:34.608892Z","shell.execute_reply.started":"2022-05-27T19:44:34.608607Z","shell.execute_reply":"2022-05-27T19:44:34.608636Z"},"trusted":true},"execution_count":null,"outputs":[]}]}